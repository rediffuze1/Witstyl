# Fix Chatbot IA en Production

## A) Cause racine

**En production Vercel, `config-direct.js` lisait uniquement depuis un fichier `.env` local qui n'existe pas. Les variables d'environnement Vercel (`process.env.OPENAI_API_KEY`) n'√©taient pas utilis√©es, causant une erreur 503 "OPENAI_UNAVAILABLE".**

## B) Fichiers modifi√©s

1. `server/config-direct.js` - Correction pour utiliser `process.env` en priorit√© (Vercel) puis fallback `.env` (local)
2. `client/src/components/floating-chatbot.tsx` - Am√©lioration gestion d'erreur avec logs d√©taill√©s
3. `server/routes/voice-agent.js` - Ajout logs de diagnostic avec requestId

## C) Code exact modifi√©

### 1. `server/config-direct.js`

```javascript
// Configuration directe sans d√©pendance dotenv
// PRIORIT√â: process.env (production Vercel) > .env local (d√©veloppement)
import { readFileSync } from 'fs';
import { join } from 'path';

let OPENAI_API_KEY = null;
let OPENAI_ORG_ID = null;
let OPENAI_PROJECT_ID = null;
let VOICE_MODE = null;
let DATABASE_URL = null;

// PRIORIT√â 1: Charger depuis process.env (production Vercel)
OPENAI_API_KEY = process.env.OPENAI_API_KEY?.trim() || null;
OPENAI_ORG_ID = process.env.OPENAI_ORG_ID?.trim() || null;
OPENAI_PROJECT_ID = process.env.OPENAI_PROJECT_ID?.trim() || null;
VOICE_MODE = process.env.VOICE_MODE?.trim() || null;
DATABASE_URL = process.env.DATABASE_URL?.trim() || null;

// PRIORIT√â 2: Fallback sur .env local (d√©veloppement uniquement)
if (!OPENAI_API_KEY || !DATABASE_URL) {
  try {
    const envPath = join(process.cwd(), '.env');
    const envContent = readFileSync(envPath, 'utf8');
    
    envContent.split('\n').forEach(line => {
      const trimmedLine = line.trim().replace(/[^\x20-\x7E]/g, '');
      if (trimmedLine && !trimmedLine.startsWith('#')) {
        const [key, ...valueParts] = trimmedLine.split('=');
        if (key && valueParts.length > 0) {
          const value = valueParts.join('=').trim();
          if (key === 'OPENAI_API_KEY' && !OPENAI_API_KEY) OPENAI_API_KEY = value;
          if (key === 'OPENAI_ORG_ID' && !OPENAI_ORG_ID) OPENAI_ORG_ID = value;
          if (key === 'OPENAI_PROJECT_ID' && !OPENAI_PROJECT_ID) OPENAI_PROJECT_ID = value;
          if (key === 'VOICE_MODE' && !VOICE_MODE) VOICE_MODE = value;
          if (key === 'DATABASE_URL' && !DATABASE_URL) DATABASE_URL = value;
        }
      }
    });
  } catch (error) {
    if (process.env.VERCEL) {
      console.log("üîß Configuration depuis process.env (Vercel)");
    } else {
      console.log("‚ö†Ô∏è Erreur chargement .env:", error.message);
    }
  }
}

console.log("üîß Configuration charg√©e");
console.log("üîë OPENAI_API_KEY:", OPENAI_API_KEY ? `‚úÖ Trouv√©e (${OPENAI_API_KEY.substring(0, 10)}...)` : "‚ùå Manquante");
console.log("üé§ VOICE_MODE:", VOICE_MODE || "off");
console.log("üóÑÔ∏è DATABASE_URL:", DATABASE_URL ? "‚úÖ Trouv√©e" : "‚ùå Manquante");
console.log("üåç Environnement:", process.env.VERCEL ? "Vercel (production)" : "Local (d√©veloppement)");

export { OPENAI_API_KEY, OPENAI_ORG_ID, OPENAI_PROJECT_ID, DATABASE_URL };
export const hasOpenAI = Boolean(OPENAI_API_KEY && OPENAI_API_KEY.length > 10);

// ... reste du fichier inchang√©
```

### 2. `client/src/components/floating-chatbot.tsx` (extrait modifi√©)

```typescript
try {
  const requestUrl = "/api/voice-agent";
  console.log('[FloatingChatbot] üì§ Envoi message:', { message: message.trim().substring(0, 50), sessionId: getSessionId() });
  
  const response = await fetch(requestUrl, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    credentials: "include", // Inclure les cookies pour la session
    body: JSON.stringify({ 
      message: message.trim(), 
      sessionId: getSessionId()
    }),
  });

  console.log('[FloatingChatbot] üì• R√©ponse re√ßue:', {
    status: response.status,
    statusText: response.statusText,
    ok: response.ok,
    url: requestUrl,
  });

  let aiResponse = "D√©sol√©, j'ai eu un souci. Comment puis-je vous aider ?";
  
  if (response.ok) {
    try {
      const data = await response.json();
      aiResponse = data.reply || data.message || "Bonjour ! Comment puis-je vous aider ?";
      console.log('[FloatingChatbot] ‚úÖ R√©ponse IA re√ßue:', aiResponse.substring(0, 100));
    } catch (parseError) {
      console.error('[FloatingChatbot] ‚ùå Erreur parsing JSON:', parseError);
      const text = await response.text();
      console.error('[FloatingChatbot] ‚ùå R√©ponse texte brute:', text.substring(0, 200));
      aiResponse = "D√©sol√©, je rencontre un probl√®me technique. Pouvez-vous r√©essayer ?";
    }
  } else {
    // Erreur HTTP avec gestion d√©taill√©e
    console.error('[FloatingChatbot] ‚ùå Erreur API:', {
      status: response.status,
      statusText: response.statusText,
      url: requestUrl,
    });
    
    let errorData = {};
    try {
      const contentType = response.headers.get("content-type");
      if (contentType && contentType.includes("application/json")) {
        errorData = await response.json();
      } else {
        const text = await response.text();
        console.error('[FloatingChatbot] ‚ùå R√©ponse non-JSON:', text.substring(0, 200));
        errorData = { message: text.substring(0, 100) };
      }
    } catch (parseError) {
      console.error('[FloatingChatbot] ‚ùå Erreur parsing erreur:', parseError);
    }
    
    console.error('[FloatingChatbot] ‚ùå D√©tails erreur:', errorData);
    
    // Message d'erreur plus sp√©cifique selon le code
    if (response.status === 503) {
      aiResponse = errorData.message || "Le service IA est temporairement indisponible. Veuillez r√©essayer dans quelques instants.";
    } else if (response.status === 500) {
      aiResponse = "Une erreur serveur est survenue. Veuillez r√©essayer plus tard.";
    } else {
      aiResponse = "D√©sol√©, je rencontre un probl√®me technique. Pouvez-vous r√©essayer ?";
    }
  }
  // ... reste du code
```

### 3. `server/routes/voice-agent.js` (extrait modifi√©)

```javascript
// POST /api/voice-agent
router.post("/", async (req, res) => {
  const requestId = Math.random().toString(36).substring(7);
  const startTime = Date.now();
  
  console.log(`[voice-agent] üì• [${requestId}] Requ√™te re√ßue:`, {
    method: req.method,
    path: req.path,
    hasBody: !!req.body,
    messageLength: req.body?.message?.length || 0,
    sessionId: req.body?.sessionId || 'none',
  });
  
  try {
    const { message, sessionId } = req.body || {};
    if (!message) {
      console.error(`[voice-agent] ‚ùå [${requestId}] Message manquant`);
      return res.status(400).json({ error: "BAD_REQUEST", message: "message manquant" });
    }
    // ... reste du code
    
  } catch (e) {
    const duration = Date.now() - startTime;
    console.error(`[voice-agent] ‚ùå [${requestId}] Erreur inattendue apr√®s ${duration}ms:`, {
      message: e.message,
      stack: e.stack?.split('\n').slice(0, 5).join('\n'),
    });
    
    if (!res.headersSent) {
      res.status(500).json({ 
        error: "SERVER_ERROR",
        message: "Une erreur interne est survenue. Veuillez r√©essayer plus tard.",
        requestId: requestId,
      });
    }
  }
});
```

## D) Checklist Vercel

### Variables d'environnement √† v√©rifier/ajouter

**Cursor ne peut pas le faire automatiquement. Voici exactement quoi ajouter :**

1. **Ouvrir Vercel Dashboard** ‚Üí Projet `Witstyl` ‚Üí Settings ‚Üí Environment Variables

2. **V√©rifier/Ajouter ces variables :**

   - `OPENAI_API_KEY` (OBLIGATOIRE)
     - Valeur : Votre cl√© API OpenAI (commence par `sk-...`)
     - Environnements : Production, Preview, Development
   
   - `OPENAI_ORG_ID` (optionnel)
     - Valeur : Votre Organization ID OpenAI si vous en avez un
     - Environnements : Production, Preview, Development
   
   - `OPENAI_PROJECT_ID` (optionnel)
     - Valeur : Votre Project ID OpenAI si vous en avez un
     - Environnements : Production, Preview, Development

3. **Apr√®s ajout/modification :**
   - Cliquer sur "Save"
   - **Redeployer** : Deployments ‚Üí Latest ‚Üí "Redeploy" (ou attendre le prochain push)

### V√©rification CORS

CORS est d√©j√† configur√© dans `server/index.ts` pour autoriser :
- `https://witstyl.vercel.app`
- `https://*.vercel.app` (tous les previews)

**Aucune action requise** si la config actuelle est correcte.

## E) Tests

### Test local

```bash
# 1. V√©rifier que .env contient OPENAI_API_KEY
cat .env | grep OPENAI_API_KEY

# 2. D√©marrer le serveur local
npm run dev

# 3. Ouvrir http://localhost:5173
# 4. Ouvrir le chatbot (bouton flottant)
# 5. Envoyer un message de test
# 6. V√©rifier la console navigateur (F12) pour les logs
# 7. V√©rifier les logs serveur pour voir "[voice-agent] ‚úÖ R√©ponse OpenAI g√©n√©r√©e"
```

### Test production (apr√®s d√©ploiement)

1. **Attendre le d√©ploiement Vercel** (2-5 minutes apr√®s push)

2. **Ouvrir https://witstyl.vercel.app**

3. **Ouvrir la console navigateur** (F12 ‚Üí Console)

4. **Ouvrir le chatbot** (bouton flottant en bas √† droite)

5. **Envoyer un message de test** (ex: "Bonjour")

6. **V√©rifier les logs console :**
   - `[FloatingChatbot] üì§ Envoi message:` doit appara√Ætre
   - `[FloatingChatbot] üì• R√©ponse re√ßue:` avec `status: 200, ok: true`
   - `[FloatingChatbot] ‚úÖ R√©ponse IA re√ßue:` avec le texte de la r√©ponse

7. **Si erreur :**
   - V√©rifier les logs Vercel : Dashboard ‚Üí Deployments ‚Üí Latest ‚Üí Logs
   - Chercher `[voice-agent]` pour voir les logs serveur
   - V√©rifier que `OPENAI_API_KEY` est bien pr√©sente dans les logs : `üîë OPENAI_API_KEY: ‚úÖ Trouv√©e (sk-...)`

8. **V√©rifier Network tab (F12 ‚Üí Network) :**
   - Requ√™te `POST /api/voice-agent` doit avoir `Status: 200`
   - Response doit contenir `{"reply": "...", "sessionId": "..."}`

## R√©sum√© des corrections

‚úÖ **Correction principale** : `config-direct.js` utilise maintenant `process.env` en priorit√© (compatible Vercel)

‚úÖ **Am√©lioration logs** : Logs d√©taill√©s c√¥t√© frontend et backend pour diagnostic

‚úÖ **Gestion d'erreur** : Messages d'erreur plus sp√©cifiques selon le code HTTP

‚úÖ **CORS** : D√©j√† configur√© correctement

‚úÖ **Route** : `/api/voice-agent` est bien expos√©e via `api/index.ts` ‚Üí `server/index.ts`

## Prochaines √©tapes

1. **Commit et push** les modifications
2. **V√©rifier/Ajouter** `OPENAI_API_KEY` dans Vercel Environment Variables
3. **Redeployer** si n√©cessaire
4. **Tester** en production selon la checklist ci-dessus

